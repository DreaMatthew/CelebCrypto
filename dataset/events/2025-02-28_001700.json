{
    "title": "Tokenized Assets Can Redefine Portfolio Management",
    "summary": "Tokenizing real-world assets on a blockchain generates the kind of daily, market-derived data that has traditionally been reserved for a narrow set of assets, says EY’s Paul Brody.",
    "time": "2025-02-28T00:17:00",
    "author": "Paul Brody",
    "content": "For decades, your investment portfolio has revolved around a key academic idea that hasn’t held up very well: efficient markets. There’s a direct line from the efficient markets theory of Eugene Fama in the 1960s to modern portfolio theory. It paved the way for index funds, a strategy that has not only weathered market cycles but also become the default for managing pensions and retirement accounts.\n\nAs we step into a new era of digital finance, tokenized assets may offer a way to broaden our investment horizons in ways that traditional models have overlooked.\n\nThe genesis of modern portfolio theory\n\nIndex fund investing didn’t arise by chance. In the early 1970s, amid vigorous debates over market efficiency, Burton Malkiel’s seminal work advocating index funds in 1973 (in his book “A Random Walk Down Wall Street”) was embodied in John Bogle’s launch of the Vanguard S&P 500 fund in 1975.\n\nThis cemented a strategy that focused on broad diversification and minimal trading. Astonishingly, passive index-investing has triumphed around the world, even though the theory underpinning it, that investors are always rational, hasn’t held up well.\n\nBehavioral psychologists like Daniel Kahneman and Amos Tversky illuminated the flaws in our decision-making processes. This is highlighted in Daniel Kahneman’s award winning book, “Thinking Fast and Slow.”\n\nIn the ensuing decades, economists have reconciled efficient markets and irrational behavior into the concept of “pretty good markets.” Aggregated wisdom in the form of prices trends towards being right, over time, though from day to day and case to case there are significant gaps that investors can exploit. Index funds have held up well because exploiting those opportunities is hard to do consistently or cheaply.\n\nAt the same time, the regulatory framework governing institutional investing reinforces this reliance on proven strategies. Fund managers operate under strict fiduciary duties that require them to prioritize client interests and mitigate risk. As a result, they allocate the bulk of their portfolios to assets with long, established track records, typically government bonds and passive equity funds.\n\nIn short, the criteria for “acceptable” investments aren’t driven solely by potential returns; they are fundamentally tied to data history, reliability, and transparency. In case you were wondering, that means index funds.\n\nIn this environment, venturing into uncharted territory is not taken lightly. New asset classes, no matter how promising, are initially sidelined because they lack the long-term, daily data that makes them viable for inclusion in a fiduciary portfolio. Until now, almost all portfolio theory has been based on U.S. equities and government bonds. Although that universe has expanded over time to include index funds and bonds from other large economies, it still represents only a relatively small portion of the world’s assets. Portfolios are constrained at the intersection of regulations and data. And that’s all going to change.\n\nTokenization: Expanding the universe of investable assets\n\nTokenization and on-chain transactions don’t just offer a scalable way to package any kind of asset. They also offer a path to transparent, comparable data on asset values. By representing real-world assets, whether it’s Thai real estate, Nigerian oil leases, or New York taxi medallions as digital tokens on a blockchain, we can begin to generate the kind of daily, market-derived data that has traditionally been reserved for a narrow set of assets.\n\nConsider a simple question: How much Thai real estate should feature in a diversified retirement portfolio? Under current models, the answer is obscured by a lack of reliable, continuous pricing data. But if Thai real estate were tokenized, establishing an on-chain market with daily closing prices, it could eventually be measured against the same metrics used for U.S. equities. In time, this would force a re-examination of the static, index-based approach that has dominated investment strategy for so long.\n\nThe implications for global finance\n\nRight now, alternative strategies – as pension fund managers refer to anything that isn’t a stock or bond index – comprise no more than 15–20% of most funds. Changing academic data on investment options would put the other 80% up for grabs.\n\nImagine a future where a truly diversified portfolio isn’t limited by the confines of traditional equity and debt markets. With tokenization, investors from large institutional funds to individual savers could gain exposure to asset classes and geographic regions previously ignored due to data scarcity or illiquidity. The principles that underpin modern portfolio theory wouldn’t be discarded. Rather, they would be expanded upon to include a broader range of risk and return profiles.\n\nAs tokenized assets build track records, fiduciaries, who today favor the predictability of bonds and index funds, might find themselves compelled to recalibrate their strategies. It’s not that the pretty good market hypothesis will be rendered obsolete. Instead, the parameters of what constitutes “efficient” may widen considerably. A richer dataset could lead to better-informed risk assessments and, ultimately, to portfolios that capture a more accurate picture of global value.\n\nA Measured but inevitable shift\n\nThis isn’t going to happen overnight. The fastest we’re likely to see changes emerge is about a decade, assuming time to build a wide portfolio of tokenized assets and 5-7 years to build a daily information track record. Once the data is present, however, change could come quickly, thanks to widespread use of artificial intelligence.\n\nOne thing that often slows the spread of change is a lack of intellectual bandwidth on the part of fund managers and consumers to adapt to new data. It took about 40 years to move pension fund investors from a 95%+ bonds model in the 1950s to a majority equity index fund model in the 1990s. It took about 30 years for index funds to become the dominant equity investment vehicle after the evidence showed they were the best option.\n\nIn a world of AI-driven automated investment tools, the transition might happen a whole lot faster. And with hundreds of trillions of dollars in assets under management, every percentage point change in allocation strategy is a little tsunami of change by itself. We’ll also be hosting a free session on the place digital assets will have in portfolios at the upcoming EY Global Blockchain Summit, 1 -3 April.",
    "url": "https://www.coindesk.com/opinion/2025/02/27/how-tokenized-assets-could-redefine-portfolio-management",
    "llm_analysis": {
        "entities": {
            "persons": [
                "Eugene Fama",
                "Burton Malkiel",
                "John Bogle",
                "Daniel Kahneman",
                "Amos Tversky",
                "Paul Brody"
            ],
            "positions": [],
            "companies": [
                "Vanguard",
                "EY"
            ],
            "organizations": []
        },
        "cryptocurrencies": [],
        "impact_sentiment": "Bullish",
        "reasoning": "The article presents tokenization as a transformative technology that will expand investment opportunities and create new markets, which is fundamentally positive for cryptocurrency adoption and utility."
    }
}